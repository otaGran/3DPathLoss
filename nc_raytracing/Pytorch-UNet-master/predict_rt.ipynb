{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--model FILE] --input INPUT [INPUT ...]\n",
      "                             [--output OUTPUT [OUTPUT ...]] [--viz]\n",
      "                             [--no-save] [--mask-threshold MASK_THRESHOLD]\n",
      "                             [--scale SCALE] [--bilinear] [--classes CLASSES]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --input/-i\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data_loading import BasicDataset\n",
    "from unet.unet_model_rt import UNet\n",
    "from utils.utils import plot_img_and_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Predict masks from input images')\n",
    "    parser.add_argument('--model', '-m', default='MODEL.pth', metavar='FILE',\n",
    "                        help='Specify the file in which the model is stored')\n",
    "    parser.add_argument('--input', '-i', metavar='INPUT', nargs='+', help='Filenames of input images', required=True)\n",
    "    parser.add_argument('--output', '-o', metavar='OUTPUT', nargs='+', help='Filenames of output images')\n",
    "    parser.add_argument('--viz', '-v', action='store_true',\n",
    "                        help='Visualize the images as they are processed')\n",
    "    parser.add_argument('--no-save', '-n', action='store_true', help='Do not save the output masks')\n",
    "    parser.add_argument('--mask-threshold', '-t', type=float, default=0.5,\n",
    "                        help='Minimum probability value to consider a mask pixel white')\n",
    "    parser.add_argument('--scale', '-s', type=float, default=0.5,\n",
    "                        help='Scale factor for the input images')\n",
    "    parser.add_argument('--bilinear', action='store_true', default=False, help='Use bilinear upsampling')\n",
    "    parser.add_argument('--classes', '-c', type=int, default=2, help='Number of classes')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def get_output_filenames(args):\n",
    "    def _generate_name(fn):\n",
    "        return f'{os.path.splitext(fn)[0]}_OUT.png'\n",
    "\n",
    "    return args.output or list(map(_generate_name, args.input))\n",
    "\n",
    "\n",
    "def mask_to_image(mask: np.ndarray, mask_values):\n",
    "    if isinstance(mask_values[0], list):\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1], len(mask_values[0])), dtype=np.uint8)\n",
    "    elif mask_values == [0, 1]:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=bool)\n",
    "    else:\n",
    "        out = np.zeros((mask.shape[-2], mask.shape[-1]), dtype=np.uint8)\n",
    "\n",
    "    if mask.ndim == 3:\n",
    "        mask = np.argmax(mask, axis=0)\n",
    "\n",
    "    for i, v in enumerate(mask_values):\n",
    "        out[mask == i] = v\n",
    "\n",
    "    return Image.fromarray(out)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "    in_files = args.input\n",
    "    out_files = get_output_filenames(args)\n",
    "\n",
    "    net = UNet(n_channels=3, n_classes=args.classes, bilinear=args.bilinear)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Loading model {args.model}')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    state_dict = torch.load(args.model, map_location=device)\n",
    "    mask_values = state_dict.pop('mask_values', [0, 1])\n",
    "    net.load_state_dict(state_dict)\n",
    "\n",
    "    logging.info('Model loaded!')\n",
    "\n",
    "    for i, filename in enumerate(in_files):\n",
    "        logging.info(f'Predicting image {filename} ...')\n",
    "        img = Image.open(filename)\n",
    "\n",
    "        mask = predict_img(net=net,\n",
    "                           full_img=img,\n",
    "                           scale_factor=args.scale,\n",
    "                           out_threshold=args.mask_threshold,\n",
    "                           device=device)\n",
    "\n",
    "        if not args.no_save:\n",
    "            out_filename = out_files[i]\n",
    "            result = mask_to_image(mask, mask_values)\n",
    "            result.save(out_filename)\n",
    "            logging.info(f'Mask saved to {out_filename}')\n",
    "\n",
    "        if args.viz:\n",
    "            logging.info(f'Visualizing results for image {filename}, close to continue...')\n",
    "            plot_img_and_mask(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/test/PycharmProjects/3DPathLoss/nc_raytracing/res/Bl_building_npy/23_24ce2187-2fbb-4503-b4b2-12d2bc028d1d.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, filename \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(in_files):\n\u001B[1;32m     35\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPredicting image \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilename\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m ...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 37\u001B[0m     building_img \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbuilding_height_map_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m40\u001B[39m:\u001B[38;5;241m1040\u001B[39m,\u001B[38;5;241m40\u001B[39m:\u001B[38;5;241m1040\u001B[39m]\n\u001B[1;32m     38\u001B[0m     terrain_img \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(terrain_height_map_dir,filename))[\u001B[38;5;241m40\u001B[39m:\u001B[38;5;241m1040\u001B[39m,\u001B[38;5;241m40\u001B[39m:\u001B[38;5;241m1040\u001B[39m]\n\u001B[1;32m     39\u001B[0m     combined_input \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mzeros((\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m2\u001B[39m, building_img\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], terrain_img\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]))\n",
      "File \u001B[0;32m~/anaconda3/envs/3DPathLoss/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001B[0m, in \u001B[0;36mload\u001B[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001B[0m\n\u001B[1;32m    403\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    404\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 405\u001B[0m     fid \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39menter_context(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mos_fspath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    406\u001B[0m     own_fid \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    408\u001B[0m \u001B[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001B[39;00m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Users/test/PycharmProjects/3DPathLoss/nc_raytracing/res/Bl_building_npy/23_24ce2187-2fbb-4503-b4b2-12d2bc028d1d.npy'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "from utils.data_loading_rt import RTDataset\n",
    "from unet.unet_model_rt import UNet\n",
    "from utils.utils import plot_img_and_mask\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "building_height_map_dir = os.path.abspath('../res/Bl_building_npy')\n",
    "terrain_height_map_dir = os.path.abspath('../res/Bl_terrain_npy')\n",
    "ground_truth_signal_strength_map_dir = os.path.abspath('./coverage_maps_building_map_test_Jun27_before_vegas_proprocessed')\n",
    "\n",
    "in_files = [\"23_24ce2187-2fbb-4503-b4b2-12d2bc028d1d.npy\"]\n",
    "\n",
    "net = UNet(n_channels=2, n_classes=1, bilinear=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# logging.info(f'Loading model {args.model}')\n",
    "logging.info(f'Using device {device}')\n",
    "net.to(device=device)\n",
    "\n",
    "state_dict = torch.load(\"/Users/test/PycharmProjects/3DPathLoss/nc_raytracing/Pytorch-UNet-master/checkpoints/checkpoint_epoch50.pth\", map_location=device)\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "logging.info('Model loaded!')\n",
    "\n",
    "for i, filename in enumerate(in_files):\n",
    "    logging.info(f'Predicting image {filename} ...')\n",
    "\n",
    "    building_img = np.load(os.path.join(building_height_map_dir,filename))[40:1040,40:1040]\n",
    "    terrain_img = np.load(os.path.join(terrain_height_map_dir,filename))[40:1040,40:1040]\n",
    "    combined_input = np.zeros((1,2, building_img.shape[0], terrain_img.shape[1]))\n",
    "    combined_input[0,0,:, :] = building_img  # Assign first channel data\n",
    "    combined_input[0,1,:, :] = terrain_img  # Assign second channel data\n",
    "\n",
    "    net.eval()\n",
    "\n",
    "    img = torch.from_numpy(combined_input)\n",
    "    #img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        output = net(img).cpu()\n",
    "\n",
    "    ground_truth = np.load(os.path.join(ground_truth_signal_strength_map_dir,filename))\n",
    "    output = output.cpu().numpy()\n",
    "\n",
    "    output = np.array(output[0,0,:,:])\n",
    "\n",
    "    print(output)\n",
    "    print(ground_truth)\n",
    "\n",
    "    import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "    # Create a figure with two subplots\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "\n",
    "    # Plot the first image in the left subplot\n",
    "    axes[0].imshow(output)\n",
    "    axes[0].set_title('Predict')\n",
    "\n",
    "    # Plot the second image in the right subplot\n",
    "    axes[1].imshow(ground_truth)\n",
    "    axes[1].set_title('Ground Truth')\n",
    "\n",
    "    # Set spacing between subplots\n",
    "    plt.subplots_adjust(wspace=0.4)\n",
    "\n",
    "    # Display the figure\n",
    "    plt.show()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "    loss = criterion(torch.from_numpy(output), torch.from_numpy(ground_truth))\n",
    "    print(\"Loss: %f\"%loss)\n",
    "\n",
    "\n",
    "    # if not args.no_save:\n",
    "    #     out_filename = out_files[i]\n",
    "    #     result = mask_to_image(mask, mask_values)\n",
    "    #     result.save(out_filename)\n",
    "    #     logging.info(f'Mask saved to {out_filename}')\n",
    "    #\n",
    "    # if args.viz:\n",
    "    #     logging.info(f'Visualizing results for image {filename}, close to continue...')\n",
    "    #     plot_img_and_mask(img, mask)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
